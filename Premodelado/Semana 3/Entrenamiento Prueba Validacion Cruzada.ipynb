{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"data:image/png;base64,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\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2025\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Train Test Split</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué es?**\n",
    "\n",
    "Es una técnica para evaluar el performance de un modelo de machine learning. \n",
    "\n",
    "Puede ser usado para problemas de clasificación y regresión y puede ser usado para cualquier algoritmo de aprendizaje supervisado. \n",
    "\n",
    "*Train set:* Datos utilizados para construir, ajustar y aprender parámetros del modelo. El modelo “ve” estos datos.\n",
    "\n",
    "*Test set:* datos mantenidos ocultos durante el entrenamiento. Se utiliza para medir qué tan bien se generaliza el modelo a datos invisibles. Esto simula predicciones del mundo real y revela un posible sobreajuste.\n",
    "\n",
    "*Validation Set:* Se utiliza para ajustar los hiperparámetros y seleccionar el mejor modelo, especialmente al construir pipelines complejos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Porqué?**\n",
    "\n",
    "La idea es ajustar un modelo en datos disponibles con entradas y salidas conocidas y luego hacer predicciones sobre nuevos datos futuros donde no tengamos la salida esperada o los valores objetivo. \n",
    "\n",
    "**¿Cuándo funciona?**\n",
    "\n",
    "Cuando tenemos suficientes datos disponibles. El procedimiento de train-test no funciona muy bien cuando los datos disponibles son pocos. \n",
    "\n",
    "La razón es que cuando el conjunto de datos se divide en conjuntos de entrenamiento y de prueba, no habrá suficientes datos en el conjunto de datos de entrenamiento para que el modelo aprenda un mapeo de entradas y salidas. \n",
    "Tampoco habrá datos suficientes en el conjunto de prueba (test) para evaluar el rendimiento del modelo\n",
    "\n",
    "**¿Qué hacer si se tienen datos insuficientes?**\n",
    "\n",
    "Una alternativa es el procedimiento de *K-fold cross-validation*\n",
    "\n",
    "\n",
    "**Entonces...¿cuándo uso el train-test split?**\n",
    "\n",
    "- Cuando nuestra base de datos es muy grande y con un solo split podemos representar la distribución general de los datos.\n",
    "- Cuando no necesitas tunear hiperparámetros por el momento\n",
    "- Si estás analizando ideas de modelos\n",
    "\n",
    "#### <font color= #2E9AFE> Configuración</font>\n",
    "\n",
    "Parámetro principal de configuración: tamaño de entrenamiento y prueba (porcentaje).\n",
    "\n",
    "Tristemente... no hay una división óptima :( \n",
    "\n",
    "Separaciones más comunes:\n",
    "- Entrenamiento: 80%, Prueba 20%\n",
    "- Entrenamiento: 70%, Prueba 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color= blue> Ejemplo de train test split para problema de CLASIFICACION</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color= #2E9AFE> Divisiones estratificadas</font>\n",
    "\n",
    "\n",
    "La mayoría de los problemas de clasificación no tienen un número balanceado de datos para cada etiqueta de clase. \n",
    "Por lo tanto es deseable dividir los datos en conjunto de entrenamiento y prueba de tal manera que se conserven las mismas proporciones de datos en cada clase observada en el conjunto de datos original. \n",
    "\n",
    "Para eso podemos usar la división estratificada de los datos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "glass_identification = fetch_ucirepo(id=42) \n",
    "  \n",
    "X = glass_identification.data.features \n",
    "y = glass_identification.data.targets \n",
    "  \n",
    "glass_data = pd.concat([X,y], axis=1)\n",
    "glass_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cuántas clases tengo en mi variable a predecir Y (tipo de vidrio)\n",
    "\n",
    "fig = px.pie(\n",
    "    glass_data,\n",
    "    names=\"Type_of_glass\",\n",
    "    title=\"Distribucion de la variable a predecir\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividir entre train y test\n",
    " = train_test_split(X, y, test_size=0.3, random_state=46, =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cuántas clases tengo en mi variable a predecir Y de entrenamiento(tipo de vidrio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recordemos** todas las transformaciones solo deben realizarse en el conjunto de entrenamiento para evitar el data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalamos los datos sólo a los datos de entrada (X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajustar regresión logística\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#crear un objeto de regresión logística\n",
    "\n",
    "#Ajustamos modelo con datos de entrenamiento\n",
    "\n",
    "#predicciones con datos de prueba -> y^\n",
    "\n",
    "\n",
    "#Evaluamos predicciones contra datos reales\n",
    "\n",
    "print('Accuracy del test: %3f' %accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un tip para saber si el modelo está sobre ajustando, es también ver las métricas del train\n",
    "\n",
    "No debe de haber demasiada diferencia entre las métricas del train y del test.\n",
    "\n",
    "Si hay mucha diferencia, quiere decir que el modelo está sobreajustando (overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algo que siempre es bueno ver también, son las métricas del train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color= blue> Ejemplo de train test split para problema de Regresion</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "housing = datasets.fetch_california_housing()\n",
    "df_housing = pd.DataFrame(housing.data,columns=housing.feature_names)\n",
    "df_housing['target'] = pd.Series(housing.target)\n",
    "df_housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividimos las X de las Y\n",
    "X = df_housing.iloc[:, :-1]\n",
    "y = df_housing.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divido datos en prueba y entrenamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalamos los datos sólo a los datos de entrada (X)\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si quisiera hacer una seleccion de variables, tambien seria despues de dividir los datos en entrenamiento y prueba\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "print(\"Variables significantes:\", X.columns[significant].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajustar regresión lineal\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#creamos el objeto de regresión lineal\n",
    "model = LinearRegression()\n",
    "#ajustamos el modelo con datos de entrenamiento\n",
    "model.fit(X_train_scaled, y_train)\n",
    "#creamos predicciones --> y^\n",
    "pred = model.predict(X_test_scaled)\n",
    "\n",
    "#Evaluamos predicciones contra datos reales\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "print('MAE: %.3f' %mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algo que siempre es bueno ver también, son las métricas del train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cuál es la desventaja de usar el procedimiento de test/train split para evaluar el modelo?\n",
    "\n",
    "Los resultados del modelo pueden variar mucho dependiendo de dónde se hizo la partición del entrenamiento y la prueba\n",
    "\n",
    "**Ejemplo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar librerías\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar datos\n",
    "iris = load_iris()\n",
    "#separar X y Y\n",
    "X=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer el train/test split con diferentes valores aleatorios\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7) #2 #7\n",
    "\n",
    "#Revisar el accuracy (precisión) de clasificación del KNN\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cómo se soluciona esto???** \n",
    "\n",
    "**Respuesta:** usamos cross validation!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= #2E9AFE> Cross Validation</font>\n",
    "\n",
    "El cross validation repite este procedimiento de dividir los datos en entrenamiento y prueba muchas veces para promediar los resultados de todos las particiones y obtener un modelo más generalizado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recomendaciones**\n",
    "\n",
    "- Con un dataset chico (<1000 filas), se recomienda usar entre 5 y 10 folds\n",
    "\n",
    "- Con un dataset mediano (1000 - 10,000 filas), se recomienda usar 5 folds\n",
    "\n",
    "- Con un dataset grande (>10,000 filas), se recomienda usar entre 3 y 5 folds\n",
    "\n",
    "- Con datasets demasiado grandes se recomienda usar mejor train/test split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color= blue> Ejemplo de K-fold cross validation para problema de Regresion</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediccion del precio de una casa\n",
    "X_house = df_housing.iloc[:, :-1]\n",
    "y_house = df_housing.iloc[:, -1]\n",
    "df_housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_housing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# KFold para regresion\n",
    "kf = KFold(n_splits=, shuffle=True, random_state=42)\n",
    "\n",
    "# Definimos modelos a probar\n",
    "regression_models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluamos cada modelo de regresion\n",
    "for name, model in regression_models.items():\n",
    "    #creamos un pipeline donde estandarizamos los datos de entrenamiento y luego aplicamos el modelo\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    scores = cross_val_score(pipeline, X_house, y_house, cv=kf, scoring='r2')\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  R² scores: {scores}\")\n",
    "    print(f\"  Mean R²: {scores.mean():.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color= blue> Ejemplo de K-fold cross validation para problema de Clasificacion </font>\n",
    "\n",
    "La mayoría de los problemas de clasificación no tienen un número balanceado de datos para cada etiqueta de clase. \n",
    "Existe una variación en el cross validation donde también podemos hacer una división estratificada de nuestra variable a predecir en cada fold. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de cáncer\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X_cancer = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y_cancer = pd.Series(data.target)\n",
    "cancer = pd.concat([X_cancer,y_cancer], axis=1)\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# inicializamos el objeto de cross validation estratificado\n",
    "skf = StratifiedKFold(n_splits=, shuffle=True, random_state=42)\n",
    "\n",
    "# Definimos los modelos a probar\n",
    "classification_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluamos cada modelo\n",
    "for name, model in classification_models.items():\n",
    "    #creamos un pipeline donde estandarizamos los datos de entrenamiento y luego aplicamos el modelo\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    scores = cross_val_score(pipeline, X_cancer, y_cancer, cv=skf, scoring='accuracy')\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Accuracy scores: {scores}\")\n",
    "    print(f\"  Mean accuracy: {scores.mean():.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas de aprendizaje\n",
    "\n",
    "Las curvas de aprendizaje muestran cómo el error del modelo varía con el tamaño del conjunto de entrenamiento. Son útiles para identificar si el modelo sufre de underfitting o overfitting.\n",
    "\n",
    "- Underfitting: Tanto el error de entrenamiento como el de validación son altos.\n",
    "- Overfitting: El error de entrenamiento es bajo, pero el error de validación es alto.\n",
    "- Balanceado: Ambos errores son bajos y cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# curva de aprendizaje\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', )\n",
    "])\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    estimator=pipeline,\n",
    "    X=X_cancer,\n",
    "    y=y_cancer,\n",
    "    cv=skf,\n",
    "    scoring='accuracy',\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    n_jobs=-1,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, 'o-', label='Training score')\n",
    "plt.plot(train_sizes, val_mean, 'o-', label='Validation score')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1)\n",
    "plt.title('Learning Curve: Logistic Regression (Breast Cancer Dataset)')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "La regresion logistica parece ser el mejor modelo para los datos de cancer de mama ya que no hace overfitting. Al contrario del random forest que sí se sobre ajusta. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
